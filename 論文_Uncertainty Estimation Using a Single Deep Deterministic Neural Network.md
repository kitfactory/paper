Abstract

我々は、1回のフォワードパスでテスト時に分布から外れたデータ点を発見し、拒否することができる決定論的なディープモデルを訓練するための手法を提案する。我々のアプローチである決定論的不確実性定量化(DUQ)は、RBFネットワークのアイデアに基づいている。新しい損失関数とセントロイド更新スキームを用いてRBFネットワークの学習をスケールアップし、ソフトマックスモデルの精度と一致させています。勾配ペナルティを使用して入力の変化の検出性を強制することで、分布から外れたデータを確実に検出することができます。我々の不確かさの定量化は大規模なデータセットによくスケールし、単一モデルを使用することで、FashionMNIST対MNIST、CIFAR-10対SVHNのような顕著な困難なデータセットのペアでの分布外れ検出において、Deep Ensemblesの精度を向上させるか、または一致させることができます。

1. 序章

不確実性を確実かつ効率的に推定することは、これまでも
のような多くの重要なアプリケーションで未解決の問題
強化学習における探索の指針として(Osband et al., 2016)、あるいはデータポイントの選択方法としてアクティブラーニングでラベルを獲得するためにet al.) これまでは、ほとんどの
深層学習の不確実性はアンサンブル（Lakshminarayananら、2017）またはモンテカルロサンプリング（Gal& Ghahramani, 2016）。) 本論文では，ディープ単一のフォワードで不確実性を見積もることができるモデルをパスします。我々は我々のモデルをDUQ、決定論的不確実性
定量化し、アイデアを再検討して構築する
90年代に元々提案されていた これらを組み合わせて
最近の進歩といくつかの改善を行っています。
最新のディープラーニングアーキテクチャのスケーラブルな学習を可能にする。我々は、ディープラーニングにおける不確実性を推定するための現在の最良のアプローチと比較して、我々のモデルを評価する。

. 我々のモデルをディープラーニングにおける不確実性推定のための現在のベストアプローチであるディープアンサンブルと比較して評価し、DUQがFashionMNIST対MNIST、CIFAR対SVHNの分布外れ（OoD）検出など、多くの評価において好ましい結果を示しました。

DUQが2つの月のデータセット上でどのように機能するかを可視化しています。
を図1に示します。DUQは、トレーニング のデータを使用すると、その確実性が低下します。ディープアンサンブルでは、アンサンブル内の異なるモデルに多様性がないため、このデータセットでは意味のある不確かさを得ることができません。私たちのコードを公開しています1
.

DUQは、ディープモデルと、異なるクラス（セントロイド）に対応する特徴ベクトルのセットで構成されています。

予測は、モデルによって計算された特徴ベクトルとセントロイドとの間の距離関数であるカーネル関数を計算することによって行われます。

このタイプのモデルはRBFネットワーク(LeCun et al., 1998a)と呼ばれ、不確実性はモデル出力と最も近いセントロイドの間の距離として測定されます。特徴ベクトルがすべてのセントロイドから遠いデータ点は、どのクラスにも属しておらず、分布から外れていると考えることができます。本論文では、不確かさを予測不確かさと定義する。

モデルは，正しいセントロイドまでの距離を最小化することによって学習されます．しかし、他のものに関しては最大化します。これにより、モデルは学習データの特徴を特定のセントロイドに近づけますが、学習データから離れた場所で何が起こるかを指示するメカニズムはありません。そのため、DUQが入力データの変化に敏感であることを確認し、分布から外れたデータを確実に検出し、分布から外れたデータを分布内の特徴表現にマッピングしないようにする必要があります（これを「特徴崩壊」と呼びます）。

この感度の上限は、モデルのLipschitz定数で定量化できます。

一般化や最適化に支障をきたす可能性があるため、感度が低すぎず、かつ高すぎないモデルを探しています。DUQは、Drucker & Le Cun (1992)が最初に導入したように、入力に対するヤコビアンを正則化することで、この結果を実現しています。

実際には、RBFネットワークは、セントロイドの不安定性と飽和損失のため、最適化が困難であることがわかっている。我々は van den Oord ら(2017)で紹介されたように、セントロイドに割り当てられたデータ点の特徴ベクトルの指数移動平均を用いてセントロイドを更新することで学習を安定化させることを提案する。

我々は、他の距離を最大化しながら、正しいセントロイドまでの距離を最小化する「1対残り」の損失関数を使用しています。この2つの変更により学習が安定し、FashionMNISTやCIFAR-10のような標準的なデータセットで設定されたsoftmaxとクロスエントロピーに近い精度になることがわかりました。

ソフトマックス出力を持つディープニューラルネットワークにおける不確実性の定量化は、一般的に予測分布のエントロピーを測定することで行われるため、すべてのクラスに一様に確率を割り当てることで最大の不確実性出力が得られます。

分布外データに対して均一な出力を達成する唯一の方法は、追加のデータで訓練を行い、テスト時にそれが分布外サンプルに一般化することを期待することです。これは実際には起こらず、softmax分布のエントロピーを見ることで確実に捕捉できる不確実性は、aleatoric uncertaintyのみであることがわかっています(Gal, 2016; Hein et al., 2019)。

DUQでは、モデル出力とすべてのセントロイドの間の距離が大きい場合、訓練中に見られるクラスのどれもが良いフィットではないことを予測することが可能です。

本論文の貢献は以下の通りである。

- 我々はRBFネットワークの学習を安定化し、この種のモデルがソフトマックスモデルと比較して競争力のある精度を達成できることを初めて示した。

- RBFネットワークの学習を安定化し、この種のモデルがソフトマックスモデルと比較して競争力のある精度を達成できることを初めて示す。

- 競合する精度を維持しながら、1回のフォワードパスで優れた不確かさを得ることができる。

2. 方法

DUQは、ResNet(He et al., 2016)のような深層特徴抽出器で構成されているが、softmax層がない。その代わりに、クラスごとに1つの学習可能な重み行列Wcを持ちます。出力とクラスのセントロイドを用いて、モデル出力とセントロイド間の指数化された距離を計算します。

式(1)

ｆθ：Ｒｍ→Ｒｄ
私たちのモデル。
m は入力次元です。
d は出力次元です。
パラメータθである。

ec は，クラス c のセントロイドであり，長さ n のベクトルである．
Wcはサイズn(セントロイドサイズ)×d(特徴抽出器の出力サイズ)の重み行列、σは長さスケールと呼ばれるハイパーパラメータです。

この関数は、放射基底関数(RBF)カーネルとも呼ばれる。クラス依存重み行列は、クラスごとに特徴の影響を受けないようにし、特徴の崩壊の可能性を最小化します。予測は，データ点 x とクラスの中心間の最大相関（最小距離）を持つクラス c を取ることによって行われます．

式２

このモデルの不確実性を、最も近いセントロイドまでの距離として定義します。

損失関数は、各クラスのカーネル値Kc(-, ec)とラベルのワンホット(2値)エンコーディングの間の2値クロスエントロピーの和です。

我々のデータセット{X, Y }の中の特定のデータ点{x, y}について。

式(3) 

ここで、K(fθ(x), ec)をKcと短縮した。学習中、データポイントのミニバッチにわたって損失を平均化し、θとW = {W1, - - - - ,Wc}に対して確率的な勾配降下を行う。クラスの中心点Eは、そのクラスに属するデータ点の特徴ベクトルの指数移動平均を用いて更新されます。

モデルパラメータ θ と W が一定であれば、この更新規則は、セントロイドの閉形解を導きます。

(4)-(6)

ここで、nc,tはミニバッチtのクラスcに割り当てられたデータ点の数、xc,t,iはクラスcを持つ時刻tのミニバッチの要素iである。γは運動量であり、通常は[0.99, 0.999]の間で設定する。

セントロイドを更新するこの方法は、定量化された潜在変数を更新するためのvan den Oordら(2017)の付録で紹介されています。高い運動量は、初期化にロバストな安定した最適化をもたらします。


提案された設定は、安定した点に収束することなく、各ミニバッチでセントロイドがさらに遠くに押し出されることになります。我々は、θのl2ノルムを正則化することでこれを回避します。
 これは、モデルを賢明な解に制限し、最適化を助けます。

2.1. Gradient Penalty

序論で述べたように、これ以上の正則化を行わないと、ディープネットワークは特徴が崩れやすくなります。我々は、勾配ペナルティを用いて表現マップを正則化することで、これを回避できることを発見した。勾配ペナルティは、一般化を支援するために、Drucker & Le Cun (1992)で最初に導入されました。最近では、このタイプのペナルティは、リップシッツ定数を正則化するために、Wasserstein GANsの訓練に成功して使用されています(Gulrajani et al., 2017)。

私たちの設定では、以下のような両面ペナルティを考えています。

(7)

ΣKcの勾配を正則化することは、fθ(x)やKc(x)（入力xのカーネル距離のベクトル）よりも効果的であることが経験的にわかりました。

同様のアプローチは Ross & Doshi-Velez (2018)によってソフトマックスモデルのために取られた。両面ペナルティはGulrajaniらによって導入された。(2017)では，片面ペナルティにもかかわらず 要件を満たすのに十分な、両面ペナルティ の方が実際には良いことが証明されました。一方的なペナルティは として定義されています。

(式8)

第4.1節では、実験的に片面ペナルティと両面ペナルティの違いを示す。両側ペナルティが感度を強制するのに理想的であることがわかります。

2.2. Intuition about Gradient Penalty(勾配罰則のイメージ)

勾配ペナルティは滑らかさを強制し、入力 x の変化に応じて関数の出力がどのくらい速く変化するかを制限します。平滑性は一般化のために重要であり，特に表現空間の距離に依存するカーネルを使用する場合に重要です．

ヤコビアンJのl2ノルムを正則化することで、少なくとも局所的にリップシッツ制約が強制されることを示すのは簡単です。

g(x + ) - g(x) ' Jg(x) ≤ ||J(x)||2|||2 となります。


//リプシッツ連続
リプシッツ連続の定義をいろいろ言い換えてみます。
・|f(x1)−f(x2)|≤k|x1−x2| となる定数 k が存在する

・関数上のどの点でも、傾き ±k の直線を引くと、関数のグラフはその間におさまっている

しかし、平滑性は、複数の入力が同じ g(x) にマップされている場合に、先に説明した特徴の崩壊問題に対して脆弱性を残します。

 リプシッツ平滑関数は入力を潰すことがあります　定数関数 g(x) = c は、任意のリップシッツ定数 L に対してリップシッツです。

崩壊は精度の向上に役立ちますが、表現空間で入力点を区別できなくなる可能性があるため、分布から外れた検出を行う能力を損なうことになります。

我々の研究では、両面ペナルティが非常に重要であることを経験的に発見しました：片面ペナルティ、すなわち、平滑性のみを強制することは、我々の表現に求める感度の高い振る舞いを生成するのに十分ではありません。これは図4bで見ることができ、図1bの両面ペナルティとは対照的です。

## 両面ペナルティで工夫した

ヤコビアンのノルムをある値以上に保つことで、直感的に学習関数の感度を高めることができます。
入力空間のすべての変化を無視して、局所的に一定の関数に崩れないようにすることで、この議論は推測的なものです。

この正則化スキームは局所的なヤコビアンに直交する方向の感度には効果がないので、この議論は推測的であり、なぜこのペナルティが感度を促進するように見えるのかを正確に説明するためには、より多くの研究が必要です。しかし、我々は経験的に、このペナルティが分布外性能を維持するために重要であることを発見しました。付録Cでは、特徴抽出器として可逆モデル（反転可能であることが保証されている）を使用したり、ベクトルKcとfθ(x)に関してヤコビアンを計算したりするなど、多くの代替アプローチを評価する。




2.3. 認識論的不確実性と偶然的不確実性

不確実性を定量化するとき、"エピステミック "と "エイリィアトォーリィク"の不確実性を区別することが有用である。エピステミック不確かさは、モデルのパラメータの不確かさに由来する。この不確実性は、分布から外れたデータの場合に高いが、例えばアクティブラーニングにおける情報的なデータポイントの場合にも高い(Houlsby et al., 2011)。

Aleatoric uncertaintyは、「3」という画像が「8」に似ているようなデータに内在する不確実性である(Smith & Gal, 2018)。この場合、真のクラスを決定することはできない。

実際には、DUQでは、他覚的不確実性と認識論的不確実性の両方を捕捉しています。非公式には、ある点が特徴空間のすべてのセントロイドから離れている場合、エピステミック不確実性が存在します。

一方、偶然的な不確かさは、特徴空間内でセントロイドが近くなるように配置し（図3参照）、その両方に近いデータ点をマッピングすることで表現されます。そうでなければ、式3に続く大きな損失が発生するので、モデルはそれらを間にマッピングしないので、セントロイドが特徴空間内で近いことが重要です。現在のところ、DUQにおけるこれら2種類の不確実性を区別するための正式な方法はありません。この問題を解決することは、今後の研究の方向性として興味深いものです。

.4. 感度が分類と対立する理由

このセクションでは、分布外れの入力を検出する際にコード化されたトレードオフと仮定のいくつかを分析する。

我々は、標準的な分類の損失が分布外れの検出に影響を与えることを、おもちゃの実験で示している。2つの特徴x1とx2、両方とも単位ガウスからサンプリングされたもので、y = sign(x1) *e、eはラベルを反転させる確率が低いノイズであるような出力yを持つ問題にモデルを適合させることを考えてみましょう。

アルゴリズムに関係なく、経験的リスクの観点から最適な決定関数は、関数 f(x1, x2) = sign(x1) です。しかし、これは分布外の振る舞いについては何も言っていません。今、入力 x1, x2 = 1, 1000 を見たらどうなるでしょうか？我々の問題の定義では，観測されたデータから標準偏差が何倍も離れているので，これは分布外となります．しかし、これは分布外れとして検出されるべきでしょうか？

データは、入力として与えられる可能性のあるものを定義していません。
 少なくとも、従来の経験的なリスク最小化のアプローチを取るならば。

このような状況では、例えば、生成モデルで行われるような判断を好むのは自然なことのように思われる。x1,x2 が医療データであれば、x2 の異常値が顕著であり、それを検出したいと考える。
しかし、もしx2が本当に無関係な変数、つまり遠い惑星の表面の温度であれば、無関係な変数の値が非常に異常な値であっても、我々のモデルはその値を無視するのが正しいと考えられます。

経験的リスク最小化を用いて訓練する場合、分類精度に関係のない特徴は、ニューラルネットワークの特徴抽出器によって単純に無視することができる。これは、我々のように距離損失を使用するような特徴空間法を使用しても、分布外検出をより困難にする。

 ここで重要なのは、分類精度との間に潜在的な緊張関係があることに注意することです。

感度を強制すると、モデルが入力の変化を表現することを強制されるため、正確な分類が難しくなる可能性があります - 上の例のように、これらは問題の因果構造とは無関係かもしれません。

 手元の問題に適した不変性がわかっている場合は、ネットワークの対応する構成によってそれを強制することができます。例えば 畳み込みネットワークを用いた翻訳不変性 本紙に掲載されています。

 ## 感度と分類のトレードオフがある

 





